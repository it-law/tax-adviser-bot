import os
import io
import base64
import asyncio
import random
import logging
import shutil
import subprocess
import tempfile
import re
from aiogram import Router, F
from aiogram.types import Message
from aiogram.filters import CommandStart, Command
from aiogram.exceptions import TelegramBadRequest

from bot.config import config
from bot.router import detect_topic
from bot.search import get_tavily_search
from bot.llm import llm_client
from bot.storage import conversation_storage

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = Router()

doc_text_by_user: dict[int, str] = {}
doc_images_by_user: dict[int, list[str]] = {}

MAX_DOC_BYTES = 200_000
MAX_DOC_CHARS = 8_000
MAX_IMAGE_ITEMS = 2
TELEGRAM_MAX_LEN = 4096

SEARCH_STATUSES = [
    "üîç –ò–∑—É—á–∞—é –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—É—é –±–∞–∑—É...",
    "üåê –ü—Ä–æ–≤–µ—Ä—è—é –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Å—É–¥–µ–±–Ω—É—é –ø—Ä–∞–∫—Ç–∏–∫—É...",
    "‚öñÔ∏è –°–≤–µ—Ä—è—é—Å—å —Å –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏ –≤ –∑–∞–∫–æ–Ω–∞—Ö...",
    "üìÇ –ü–æ–¥–Ω–∏–º–∞—é –∞—Ä—Ö–∏–≤—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...",
]

GENERATING_STATUSES = [
    "üìù –§–æ—Ä–º—É–ª–∏—Ä—É—é —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ...",
    "ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã...",
    "üí° –ì–æ—Ç–æ–≤–ª—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –≤–∞—Å...",
    "‚úçÔ∏è –ü–∏—à—É –æ—Ç–≤–µ—Ç...",
]

SEARCH_KEYWORDS = [
    "—Å–∞–Ω–∫—Ü",
    "–Ω–¥–ø–∏",
    "–∏–∑–º–µ–Ω–µ–Ω–∏",
    "–∑–∞–∫–æ–Ω",
    "–Ω–æ–≤–æ—Å—Ç",
    "—É–∫–∞–∑",
    "–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω",
    "–ø–∏—Å—å–º–æ",
    "–ø—Ä–∞–∫—Ç–∏–∫",
    "–∏—Å—Ç–æ—á–Ω–∏–∫",
    "—Å—Å—ã–ª–∫–∞",
    "—Ñ–Ω—Å",
    "–º–∏–Ω—Ñ–∏–Ω",
]

@router.message(CommandStart())
async def cmd_start(message: Message):
    conversation_storage.clear_history(message.from_user.id)
    doc_text_by_user.pop(message.from_user.id, None)
    doc_images_by_user.pop(message.from_user.id, None)
    await message.answer(
        "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –Ω–∞–ª–æ–≥–∞–º –≤ –†–§.\n\n"
        "–û–ø–∏—à–∏—Ç–µ –≤–∞—à—É —Å–∏—Ç—É–∞—Ü–∏—é –∏–ª–∏ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—á—É –ø–æ —Å—É—Ç–∏.\n"
        "–ú–æ–∂–Ω–æ –ø—Ä–∏—Å–ª–∞—Ç—å —Ç–µ–∫—Å—Ç, —Ñ–æ—Ç–æ, DOCX –∏–ª–∏ DOC ‚Äî —è —É—á—Ç—É —ç—Ç–æ –≤ –æ—Ç–≤–µ—Ç–∞—Ö.\n\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        "‚Ä¢ –ù–∞–ª–æ–≥ –Ω–∞ –∏–º—É—â–µ—Å—Ç–≤–æ –¥–ª—è —Ñ–∏–∑–ª–∏—Ü –≤ –º–æ–µ–º —Å–ª—É—á–∞–µ\n"
        "‚Ä¢ –£ –º–µ–Ω—è –ò–ü –Ω–∞ –£–°–ù, —á—Ç–æ —Å –ù–î–°?\n"
        "‚Ä¢ –ß—Ç–æ –≥—Ä–æ–∑–∏—Ç –∑–∞ –ø—Ä–æ—Å—Ä–æ—á–∫—É –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏?\n\n"
        "–ö–æ–º–∞–Ω–¥–∞: /clear ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç."
    )

@router.message(Command("clear"))
async def cmd_clear(message: Message):
    conversation_storage.clear_history(message.from_user.id)
    doc_text_by_user.pop(message.from_user.id, None)
    doc_images_by_user.pop(message.from_user.id, None)
    await message.answer("üßπ –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω.")

def _safe_trim(text: str, limit: int) -> str:
    if len(text) <= limit:
        return text
    return text[:limit]

def _is_image_file(file_name: str, mime_type: str) -> bool:
    file_name = (file_name or "").lower()
    mime_type = (mime_type or "").lower()
    return mime_type.startswith("image/") or file_name.endswith((".png", ".jpg", ".jpeg", ".webp", ".bmp", ".tiff"))

def _is_docx_file(file_name: str, mime_type: str) -> bool:
    file_name = (file_name or "").lower()
    mime_type = (mime_type or "").lower()
    return (
        file_name.endswith(".docx")
        or mime_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )

def _is_doc_file(file_name: str, mime_type: str) -> bool:
    file_name = (file_name or "").lower()
    mime_type = (mime_type or "").lower()
    return file_name.endswith(".doc") or mime_type == "application/msword"

def _to_data_url(data: bytes, mime_type: str) -> str:
    b64 = base64.b64encode(data).decode("ascii")
    return f"data:{mime_type};base64,{b64}"

def _read_docx_bytes(data: bytes) -> str:
    try:
        from docx import Document
    except Exception as e:
        logger.info(f"DOCX deps missing: {e}")
        return ""

    try:
        doc = Document(io.BytesIO(data))
        parts = [p.text.strip() for p in doc.paragraphs if p.text and p.text.strip()]
        return "\n".join(parts).strip()
    except Exception as e:
        logger.error(f"DOCX parse error: {e}")
        return ""

def _read_doc_bytes(data: bytes) -> tuple[str, str | None]:
    tool = None
    if shutil.which("antiword"):
        tool = "antiword"
    elif shutil.which("catdoc"):
        tool = "catdoc"

    if not tool:
        return "", "missing_tool"

    tmp_path = ""
    try:
        with tempfile.NamedTemporaryFile(suffix=".doc", delete=False) as tmp:
            tmp.write(data)
            tmp_path = tmp.name

        if tool == "antiword":
            res = subprocess.run([tool, tmp_path], capture_output=True, text=True)
        else:
            res = subprocess.run([tool, "-w", tmp_path], capture_output=True, text=True)

        if res.returncode != 0:
            return "", "parse_error"
        return (res.stdout or "").strip(), None
    except Exception as e:
        logger.error(f"DOC parse error: {e}")
        return "", "parse_error"
    finally:
        if tmp_path:
            try:
                os.unlink(tmp_path)
            except Exception:
                pass

def _store_user_image(user_id: int, data_url: str):
    images = doc_images_by_user.get(user_id, [])
    images.append(data_url)
    if len(images) > MAX_IMAGE_ITEMS:
        images = images[-MAX_IMAGE_ITEMS:]
    doc_images_by_user[user_id] = images

def _split_message(text: str, limit: int = TELEGRAM_MAX_LEN) -> list[str]:
    if len(text) <= limit:
        return [text]
    parts: list[str] = []
    remaining = text
    while len(remaining) > limit:
        cut = remaining.rfind("\n", 0, limit + 1)
        if cut == -1:
            cut = remaining.rfind(" ", 0, limit + 1)
        if cut == -1 or cut < limit * 0.3:
            cut = limit
        parts.append(remaining[:cut].strip())
        remaining = remaining[cut:].lstrip()
    if remaining:
        parts.append(remaining)
    return parts

def needs_web_search(user_query: str) -> bool:
    q = user_query.strip().lower()
    if not q:
        return False
    if len(q) > 50:
        return True
    return any(word in q for word in SEARCH_KEYWORDS)

def _extract_urls(text: str) -> list[str]:
    if not text:
        return []
    urls = re.findall(r"https?://\\S+", text)
    cleaned: list[str] = []
    seen = set()
    for url in urls:
        u = url.rstrip(").,;!?:\"'‚Äù¬ª")
        if u not in seen:
            seen.add(u)
            cleaned.append(u)
    return cleaned

async def process_query(message: Message, user_query: str, extra_context: str = ""):
    user_id = message.from_user.id
    status_msg = await message.answer("‚è≥ –ü—Ä–∏–Ω—è–ª –∑–∞–ø—Ä–æ—Å, –Ω–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑...")

    async def update_status(text):
        try:
            await status_msg.edit_text(f"‚è≥ {text}")
        except Exception:
            pass

    try:
        topic = detect_topic(user_query)
        
        law_file = config.LAW_FILES.get(topic, config.LAW_FILES["tax"])
        law_path = os.path.join(config.DATA_DIR, law_file)
        law_context = ""
        
        try:
            if os.path.exists(law_path):
                with open(law_path, "r", encoding="utf-8") as f:
                    law_context = f.read()[:50000]
        except Exception as e:
            logger.error(f"Error reading law file: {e}")

        web_results = ""
        if needs_web_search(user_query):
            await update_status(random.choice(SEARCH_STATUSES))
            try:
                web_results = await asyncio.wait_for(
                    get_tavily_search(user_query),
                    timeout=20.0
                )
            except asyncio.TimeoutError:
                logger.error("Tavily search timeout")
                web_results = ""
            except Exception as e:
                logger.error(f"Tavily search error: {e}")
                web_results = ""

        await update_status(random.choice(GENERATING_STATUSES))
        
        history = conversation_storage.get_formatted_history(user_id)
        if extra_context:
            doc_block = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞:\n{extra_context}"
            history = f"{history}\n\n{doc_block}" if history else doc_block
        elif doc_text_by_user.get(user_id):
            doc_block = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞:\n{doc_text_by_user[user_id]}"
            history = f"{history}\n\n{doc_block}" if history else doc_block

        prompt = llm_client.build_prompt(
            user_query=user_query,
            law_context=law_context,
            web_results=web_results,
            history=history,
        )

        try:
            answer = await asyncio.wait_for(
                llm_client.generate_response(prompt, image_urls=doc_images_by_user.get(user_id)),
                timeout=90.0
            )
        except asyncio.TimeoutError:
            answer = "‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ —É—Å–ø–µ–ª–∞ –æ—Ç–≤–µ—Ç–∏—Ç—å –≤–æ–≤—Ä–µ–º—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –≤–æ–ø—Ä–æ—Å."

        urls = _extract_urls(web_results if isinstance(web_results, str) else "")
        if urls and "–∏—Å—Ç–æ—á–Ω–∏–∫–∏" not in answer.lower():
            sources = "<b>–ò—Å—Ç–æ—á–Ω–∏–∫–∏:</b><br>" + "<br>".join(
                f"‚Ä¢ <a href=\"{u}\">–ò—Å—Ç–æ—á–Ω–∏–∫ {i}</a>" for i, u in enumerate(urls, 1)
            )
            answer = answer.rstrip() + "\n\n" + sources
        
        conversation_storage.add_message(user_id, "user", user_query)
        conversation_storage.add_message(user_id, "assistant", answer)

        try:
            await status_msg.delete()
        except Exception:
            pass

        for part in _split_message(answer):
            await message.answer(part)

    except Exception as e:
        logger.error(f"Global handler error: {e}")
        try:
            await status_msg.delete()
        except Exception:
            pass
        await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

@router.message(F.photo)
async def handle_photo(message: Message):
    caption = (message.caption or "").strip()
    image_url = ""
    try:
        photo = message.photo[-1]
        buf = io.BytesIO()
        await message.bot.download(photo, destination=buf)
        buf.seek(0)
        data = buf.read()
        if len(data) <= MAX_DOC_BYTES:
            image_url = _to_data_url(data, "image/jpeg")
            _store_user_image(message.from_user.id, image_url)
    except Exception as e:
        logger.error(f"Photo download error: {e}")

    if caption:
        if image_url:
            await message.answer("–§–æ—Ç–æ –ø–æ–ª—É—á–∏–ª. –û—Ç–≤–µ—á–∞—é –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É.")
            await process_query(message, caption)
        else:
            await message.answer(
                "–§–æ—Ç–æ –ø–æ–ª—É—á–∏–ª. –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å. "
                "–ü—Ä–∏—à–ª–∏—Ç–µ –±–æ–ª–µ–µ –ª–µ–≥–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
            )
            await process_query(message, caption)
        return

    if image_url:
        await message.answer(
            "–§–æ—Ç–æ –ø–æ–ª—É—á–∏–ª. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—á—É —Å —É—á–µ—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."
        )
    else:
        await message.answer(
            "–§–æ—Ç–æ –ø–æ–ª—É—á–∏–ª. –ù–∞–ø–∏—à–∏—Ç–µ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –≤—ã—è—Å–Ω–∏—Ç—å, –∏, –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç, –ø–µ—Ä–µ–ø–µ—á–∞—Ç–∞–π—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã."
        )

@router.message(F.document)
async def handle_document(message: Message):
    doc = message.document
    caption = (message.caption or "").strip()
    file_name = (doc.file_name or "").lower()
    mime_type = (doc.mime_type or "").lower()

    text_context = ""
    image_url = ""
    if doc.file_size and doc.file_size > MAX_DOC_BYTES:
        await message.answer(
            "–î–æ–∫—É–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü—Ä–∏—à–ª–∏—Ç–µ –∫—Ä–∞—Ç–∫–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª."
        )
    else:
        is_text = mime_type.startswith("text/") or file_name.endswith((".txt", ".md", ".csv"))
        if is_text:
            try:
                buf = io.BytesIO()
                await message.bot.download(doc, destination=buf)
                buf.seek(0)
                text_context = buf.read().decode("utf-8", errors="ignore").strip()
                text_context = _safe_trim(text_context, MAX_DOC_CHARS)
            except Exception as e:
                logger.error(f"Document download/read error: {e}")
                text_context = ""
        elif _is_docx_file(file_name, mime_type):
            try:
                buf = io.BytesIO()
                await message.bot.download(doc, destination=buf)
                buf.seek(0)
                text_context = _read_docx_bytes(buf.read())
                text_context = _safe_trim(text_context, MAX_DOC_CHARS)
            except Exception as e:
                logger.error(f"DOCX download/read error: {e}")
                text_context = ""
        elif _is_doc_file(file_name, mime_type):
            try:
                buf = io.BytesIO()
                await message.bot.download(doc, destination=buf)
                buf.seek(0)
                text_context, doc_err = _read_doc_bytes(buf.read())
                text_context = _safe_trim(text_context, MAX_DOC_CHARS)
                if not text_context and doc_err == "missing_tool":
                    await message.answer(
                        "DOC –ø–æ–ª—É—á–µ–Ω, –Ω–æ –¥–ª—è —á—Ç–µ–Ω–∏—è –Ω—É–∂–µ–Ω <code>antiword</code> –∏–ª–∏ <code>catdoc</code>. "
                        "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏–ª–∏ –ø—Ä–∏—à–ª–∏—Ç–µ DOCX/—Ç–µ–∫—Å—Ç."
                    )
            except Exception as e:
                logger.error(f"DOC download/read error: {e}")
                text_context = ""
        elif _is_image_file(file_name, mime_type):
            try:
                buf = io.BytesIO()
                await message.bot.download(doc, destination=buf)
                buf.seek(0)
                data = buf.read()
                if len(data) <= MAX_DOC_BYTES:
                    image_url = _to_data_url(data, mime_type or "image/jpeg")
                    _store_user_image(message.from_user.id, image_url)
                else:
                    text_context = ""
            except Exception as e:
                logger.error(f"Image document download error: {e}")
                text_context = ""
        else:
            await message.answer(
                "–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–ª—É—á–∏–ª. –°–µ–π—á–∞—Å —á–∏—Ç–∞—é —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã, DOC/DOCX –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. "
                "–ï—Å–ª–∏ —ç—Ç–æ PDF, –ø—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç –∏–ª–∏ —Å–∫—Ä–∏–Ω—à–æ—Ç—ã —Å—Ç—Ä–∞–Ω–∏—Ü."
            )

    if caption:
        if text_context:
            doc_text_by_user[message.from_user.id] = text_context
            await message.answer("–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–ª—É—á–∏–ª, –æ—Ç–≤–µ—á–∞—é –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É.")
            await process_query(message, caption, extra_context=text_context)
        elif doc_images_by_user.get(message.from_user.id):
            await message.answer("–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–ª—É—á–∏–ª. –û—Ç–≤–µ—á–∞—é –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É.")
            await process_query(message, caption)
        else:
            await message.answer(
                "–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–ª—É—á–∏–ª, –Ω–æ —Ç–µ–∫—Å—Ç –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω. –û—Ç–≤–µ—á—É –ø–æ –≤–æ–ø—Ä–æ—Å—É, "
                "–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã."
            )
            await process_query(message, caption)
        return

    if text_context:
        doc_text_by_user[message.from_user.id] = text_context
        await message.answer(
            "–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–ª—É—á–µ–Ω. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –Ω–µ–º—É ‚Äî –æ—Ç–≤–µ—á—É."
        )
    elif doc_images_by_user.get(message.from_user.id):
        await message.answer(
            "–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–ª—É—á–µ–Ω. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—á—É —Å —É—á–µ—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."
        )
    else:
        await message.answer(
            "–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–ª—É—á–µ–Ω. –ù–∞–ø–∏—à–∏—Ç–µ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –≤—ã—è—Å–Ω–∏—Ç—å, –∏ –ø—Ä–∏–ª–æ–∂–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã."
        )

@router.message(F.text)
async def handle_question(message: Message):
    if message.text.startswith("/"):
        return

    user_id = message.from_user.id
    extra_context = doc_text_by_user.get(user_id, "")
    await process_query(message, message.text, extra_context=extra_context)
