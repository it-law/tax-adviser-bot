import httpx
from openai import AsyncOpenAI
from bot.config import config

class LLMClient:
    def __init__(self):
        if config.OPENROUTER_API_KEY:
            # ‚úÖ –í–ê–ñ–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–π–º–∞—É—Ç—ã
            # connect: –≤—Ä–µ–º—è –Ω–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å —Å–µ—Ä–≤–µ—Ä–æ–º
            # read: —Å–∫–æ–ª—å–∫–æ –∂–¥–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞ (—Å—Ç–∞–≤–∏–º 90 —Å–µ–∫, —á—Ç–æ–±—ã Llama —É—Å–ø–µ–ª–∞ –ø–æ–¥—É–º–∞—Ç—å)
            timeout = httpx.Timeout(
                connect=10.0,
                read=90.0, 
                write=10.0,
                pool=10.0,
            )
            
            # –ü–µ—Ä–µ–¥–∞–µ–º timeout –≤ –∫–ª–∏–µ–Ω—Ç
            http_client = httpx.AsyncClient(timeout=timeout)

            self.client = AsyncOpenAI(
                api_key=config.OPENROUTER_API_KEY,
                base_url=config.OPENROUTER_BASE_URL,
                http_client=http_client,
            )
        else:
            self.client = None

    # üëá –≠–¢–û–¢ –ú–ï–¢–û–î –û–°–¢–ê–í–õ–Ø–ï–ú –ö–ê–ö –ë–´–õ –£ –í–ê–° (–æ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π)
    def build_prompt(self, user_query: str, law_context: str, web_results: str, history: str) -> str:
        prompt = f"""
–¢—ã ‚Äî –≤—ã—Å–æ–∫–æ–∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–ª–æ–≥–æ–≤—ã–π —é—Ä–∏—Å—Ç-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç (AI Legal Tax Assistant), —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏.

1. –ò—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ –∏–∑ (–∑–∞–∫–æ–Ω—ã –ù–ö –†–§) –∫–∞–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç.
2. –î–æ–ø–æ–ª–Ω—è–π –æ—Ç–≤–µ—Ç –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ (–ø—Ä–∞–∫—Ç–∏–∫–∞, –ø–∏—Å—å–º–∞ –ú–∏–Ω—Ñ–∏–Ω–∞/–§–ù–°).
3. –¶–∏—Ç–∏—Ä—É–π —Å—Ç–∞—Ç—å–∏ –∑–∞–∫–æ–Ω–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "—Å–æ–≥–ª–∞—Å–Ω–æ –ø. 3 —Å—Ç. 346.11 –ù–ö –†–§").
4. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç: –°—É—Ç—å -> –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ -> –ü—Ä–∞–∫—Ç–∏–∫–∞ -> –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è.
5. –ï—Å–ª–∏ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.

{law_context}

{web_results}

{history}

{user_query}

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –∏—Å–ø–æ–ª—å–∑—É—è Markdown.
–í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤—å: "_–û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –ò–ò. –ù–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–µ–π._"
"""
        return prompt

    async def generate_response(self, prompt: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenRouter"""
        if not self.client:
            return "‚ùå –û—à–∏–±–∫–∞: API –∫–ª—é—á OpenRouter –Ω–µ –Ω–∞–π–¥–µ–Ω."

        try:
            response = await self.client.chat.completions.create(
                model=config.MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=2000,
            )
            return response.choices[0].message.content
        except Exception as e:
            # –¢–µ–ø–µ—Ä—å –æ—à–∏–±–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –±—É–¥–µ—Ç –æ—Ç–ª–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –∑–¥–µ—Å—å, –∞ –Ω–µ –≤–µ—à–∞—Ç—å –±–æ—Ç–∞
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–≤–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞): {str(e)}"

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç
llm_client = LLMClient()
